{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86112d0b-0ffd-418e-9a3d-9e1f97c180a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.19.0-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m198.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf in /opt/app-root/lib/python3.9/site-packages (from onnxruntime) (3.20.3)\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m228.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.13.2-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m176.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: flatbuffers in /opt/app-root/lib/python3.9/site-packages (from onnxruntime) (24.3.25)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /opt/app-root/lib/python3.9/site-packages (from onnxruntime) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/app-root/lib/python3.9/site-packages (from onnxruntime) (24.1)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m267.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m339.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, humanfriendly, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 mpmath-1.3.0 onnxruntime-1.19.0 sympy-1.13.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 13:11:01.657664: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-28 13:11:01.657726: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-28 13:11:01.659102: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-28 13:11:01.666827: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-28 13:11:02.577425: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime\n",
    "\n",
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import utils\n",
    "import onnxruntime as ort\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6a3fea5-b542-4839-851f-b5a80167dda3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unzip_file(zip_file_path, extract_to_dir):\n",
    "    if not os.path.exists(extract_to_dir):\n",
    "        os.makedirs(extract_to_dir)\n",
    "\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to_dir)\n",
    "\n",
    "    print(f\"Files extracted to: {extract_to_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9770af0-4630-421b-b4e2-6fc5f9cd9a44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to: train\n"
     ]
    }
   ],
   "source": [
    "zip_file_path = 'images_zipped.zip'\n",
    "extract_to_dir = 'train'\n",
    "unzip_file(zip_file_path, extract_to_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35799d6c-bb5b-407b-a4f8-e24571b17e59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to: modals\n"
     ]
    }
   ],
   "source": [
    "zip_file_path = 'modals.zip'\n",
    "extract_to_dir = 'modals'\n",
    "unzip_file(zip_file_path, extract_to_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7cbcb43-1cad-40c5-9ba9-0957cbfbb8e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_data = 'train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7030c5bb-464c-4579-a07e-4fd5886b7308",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1129 files belonging to 10 classes.\n",
      "Using 112 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_data=utils.image_dataset_from_directory(\n",
    "    path_to_data,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    validation_split=0.1,\n",
    "    subset=\"validation\",\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(256,256),\n",
    "    batch_size=64,\n",
    "    seed=40,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4ab1620-9050-4c61-9664-b4ccf97671d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of train images:  (64, 256, 256, 3)\n",
      "Amount of train labels:  (64,)\n"
     ]
    }
   ],
   "source": [
    "for images,lables in val_data.take(1):\n",
    "  print('Amount of train images: ', images.shape)\n",
    "  print('Amount of train labels: ', lables.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98fc5770-b0de-4660-9283-543cdc3d2fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize(image, label):\n",
    "  return image/255.0, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a3641f8-c729-426e-9bf0-e8d96ea2775f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_data= val_data.map(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1bc7988-b902-4837-8c67-66d12fca0313",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_x=[]\n",
    "val_y=[]\n",
    "\n",
    "for image,label in val_data:\n",
    "   val_x.append(image)\n",
    "   val_y.append(label)\n",
    "\n",
    "val_x = tf.concat(val_x, axis=0)\n",
    "val_y = tf.concat(val_y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccb2da3c-51f1-49c7-af3d-b6149fdc7d30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "val_y = tf.keras.utils.to_categorical(val_y, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2eb45563-64ee-476e-a645-9cd7d0c20646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_model_file(folder_path):\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('.onnx'):\n",
    "            return file\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4340c87e-90ba-425b-87fe-3cc92cfb6745",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model_name = find_model_file('modals/newmodal')\n",
    "production_model_name = find_model_file('modals/production')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "264112f5-fce2-4f44-a4d0-02b348a09dcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model = f\"modals/newmodal/{new_model_name}\"\n",
    "new_model_session = ort.InferenceSession(new_model)\n",
    "\n",
    "production_model = f\"modals/production/{production_model_name}\"\n",
    "production_model_session = ort.InferenceSession(production_model)\n",
    "\n",
    "new_model_input = new_model_session.get_inputs()[0].name\n",
    "new_model_output = new_model_session.get_outputs()[0].name\n",
    "\n",
    "production_model_input = production_model_session.get_inputs()[0].name\n",
    "production_model_output = production_model_session.get_outputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8ebc5fe-ea9f-4f71-966f-47feda670166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_137/3769232995.py:5: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity with explicit device placement instead.\n"
     ]
    }
   ],
   "source": [
    "new_pred_arr = []\n",
    "production_pred_arr = []\n",
    "\n",
    "for i, val in enumerate(val_x):\n",
    "    new_model_pred = new_model_session.run([new_model_output], {new_model_input: [val_x[i].cpu().numpy()]})\n",
    "    production_model_pred = production_model_session.run([production_model_output], {production_model_input: [val_x[i].cpu().numpy()]})\n",
    "\n",
    "    new_pred_arr.append(new_model_pred)\n",
    "    production_pred_arr.append(production_model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5b77b73-426e-4aa9-b4a3-1efa054669b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Model Accuracy: 78.57%\n",
      "Production Model Accuracy: 62.50%\n",
      "\n",
      "New Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.57      0.70        14\n",
      "           1       0.75      1.00      0.86        21\n",
      "           2       0.60      0.90      0.72        10\n",
      "           3       0.80      0.80      0.80        10\n",
      "           4       1.00      0.78      0.88         9\n",
      "           5       0.86      0.75      0.80         8\n",
      "           6       0.40      0.50      0.44         4\n",
      "           7       0.83      0.50      0.62        10\n",
      "           8       0.84      0.84      0.84        19\n",
      "           9       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.79       112\n",
      "   macro avg       0.80      0.75      0.76       112\n",
      "weighted avg       0.81      0.79      0.78       112\n",
      "\n",
      "\n",
      "Production Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.50      0.56        14\n",
      "           1       0.61      0.90      0.73        21\n",
      "           2       0.43      0.60      0.50        10\n",
      "           3       0.40      0.40      0.40        10\n",
      "           4       0.50      0.67      0.57         9\n",
      "           5       0.55      0.75      0.63         8\n",
      "           6       1.00      0.25      0.40         4\n",
      "           7       1.00      0.40      0.57        10\n",
      "           8       0.93      0.74      0.82        19\n",
      "           9       1.00      0.43      0.60         7\n",
      "\n",
      "    accuracy                           0.62       112\n",
      "   macro avg       0.71      0.56      0.58       112\n",
      "weighted avg       0.69      0.62      0.62       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_pred_arr = np.concatenate([np.argmax(pred[0], axis=1) for pred in new_pred_arr], axis=0)\n",
    "production_pred_arr = np.concatenate([np.argmax(pred[0], axis=1) for pred in production_pred_arr], axis=0)\n",
    "\n",
    "val_y_flat = np.argmax(val_y, axis=1)\n",
    "\n",
    "new_model_accuracy = accuracy_score(val_y_flat, new_pred_arr)\n",
    "production_model_accuracy = accuracy_score(val_y_flat, production_pred_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c4f9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "should_replace = new_model_accuracy > production_model_accuracy\n",
    "\n",
    "with open('should_replace.json', 'w') as f:\n",
    "    json.dump({'replace': should_replace}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "592aa7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files zipped into 'replacement.zip'.\n"
     ]
    }
   ],
   "source": [
    "new_model_folder = 'modals/newmodal'\n",
    "replacement_zip = 'replacement.zip'\n",
    "\n",
    "with zipfile.ZipFile(replacement_zip, 'w') as zipf:\n",
    "    zipf.write('should_replace.json')\n",
    "\n",
    "    if should_replace:\n",
    "        for root, dirs, files in os.walk(new_model_folder):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(file_path, new_model_folder)\n",
    "                zipf.write(file_path, arcname)\n",
    "\n",
    "print(f\"Files zipped into '{replacement_zip}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba338e1f-34b0-410a-a941-6ce726d9c589",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to model_comparison_20240828_141815.txt\n"
     ]
    }
   ],
   "source": [
    "filename = 'model_comparison.txt'\n",
    "\n",
    "with open(filename, 'w') as file:\n",
    "    file.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "    file.write(f\"New Model Name: {new_model_name}\\n\")\n",
    "    file.write(f\"New Model Accuracy: {new_model_accuracy * 100:.2f}%\\n\\n\")\n",
    "    file.write(f\"Production Model Name: {production_model_name}\\n\")\n",
    "    file.write(f\"Production Model Accuracy: {production_model_accuracy * 100:.2f}%\\n\")\n",
    "\n",
    "    file.write(\"\\nNew Model Classification Report:\\n\")\n",
    "    file.write(classification_report(val_y_flat, new_pred_arr, zero_division=0))\n",
    "\n",
    "    file.write(\"\\nProduction Model Classification Report:\\n\")\n",
    "    file.write(classification_report(val_y_flat, production_pred_arr, zero_division=0))\n",
    "\n",
    "print(f\"Results saved to {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
